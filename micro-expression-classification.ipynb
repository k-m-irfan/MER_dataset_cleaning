{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Micro-Expressions Classification","metadata":{}},{"cell_type":"code","source":"# importing required libraries\nimport os\nimport torch\nimport torchvision\nfrom torch.utils.data import random_split\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import ToTensor\nimport torchvision.transforms as tt","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:04:39.159844Z","iopub.execute_input":"2022-03-23T08:04:39.160265Z","iopub.status.idle":"2022-03-23T08:04:39.747882Z","shell.execute_reply.started":"2022-03-23T08:04:39.160165Z","shell.execute_reply":"2022-03-23T08:04:39.747100Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Classes","metadata":{}},{"cell_type":"code","source":"# Classes\ndatasetDir = \"../input/micro-expressions/Micro_Expressions\"\nclasses = os.listdir(datasetDir + \"/train\")\nprint(\"Expression Labels: \",classes)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:04:39.749632Z","iopub.execute_input":"2022-03-23T08:04:39.749929Z","iopub.status.idle":"2022-03-23T08:04:39.762814Z","shell.execute_reply.started":"2022-03-23T08:04:39.749891Z","shell.execute_reply":"2022-03-23T08:04:39.761816Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Using Data Augmentation to increase dataset size (reflect-padding, and random-horizontal flip)","metadata":{}},{"cell_type":"code","source":"# data augmentation (reflect-padding, and random-horizontal flip)\ntfms = tt.Compose([tt.RandomCrop(80, padding=15, padding_mode='reflect'),\n                        tt.RandomHorizontalFlip(),\n                        tt.ToTensor()])\n#Loading the dataset as pyTorch Tensors\ndataset1 = ImageFolder(datasetDir+\"/train\",tfms)\ndataset2 = ImageFolder(datasetDir+\"/train\",transform=ToTensor())\n#Combining normal dataset and augmented dataset\ndataset = dataset1+dataset2\ndataset.classes = ['anger', 'disgust', 'fear', 'happiness', 'neutral', 'sadness', 'surprise']","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:04:39.764141Z","iopub.execute_input":"2022-03-23T08:04:39.764575Z","iopub.status.idle":"2022-03-23T08:04:40.448208Z","shell.execute_reply.started":"2022-03-23T08:04:39.764537Z","shell.execute_reply":"2022-03-23T08:04:40.447391Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing data","metadata":{}},{"cell_type":"code","source":"# visualising dataset\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef show_image(image, label):\n    print(\"Label: \",dataset.classes[label])\n    plt.imshow(image.permute(1,2,0)) #rgb channel at last in matplot (1st in PyTorch Tensor)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:04:40.450569Z","iopub.execute_input":"2022-03-23T08:04:40.450849Z","iopub.status.idle":"2022-03-23T08:04:40.457862Z","shell.execute_reply.started":"2022-03-23T08:04:40.450810Z","shell.execute_reply":"2022-03-23T08:04:40.456887Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# an example from the dataset\nshow_image(*dataset[100])","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:04:40.459438Z","iopub.execute_input":"2022-03-23T08:04:40.459995Z","iopub.status.idle":"2022-03-23T08:04:40.698312Z","shell.execute_reply.started":"2022-03-23T08:04:40.459958Z","shell.execute_reply":"2022-03-23T08:04:40.697626Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Training and Validation Set","metadata":{}},{"cell_type":"code","source":"# Splitting dataset into training and validataion set using random_split\nrandomSeed = 3 #to always create same validation set\ntorch.manual_seed(randomSeed)\nvalSize = 2000\ntrainSize = len(dataset)-valSize\ntrainDS, valDS = random_split(dataset,[trainSize,valSize])\nprint(\"No. of training data: \",len(trainDS))\nprint(\"No. of validation data: \",len(valDS))","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:04:40.699323Z","iopub.execute_input":"2022-03-23T08:04:40.699579Z","iopub.status.idle":"2022-03-23T08:04:40.710484Z","shell.execute_reply.started":"2022-03-23T08:04:40.699541Z","shell.execute_reply":"2022-03-23T08:04:40.709696Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#Creating data loaders\nfrom torch.utils.data.dataloader import DataLoader\nbatchSize = 200\ntrainDL = DataLoader(trainDS,batchSize,shuffle=True,num_workers=4, pin_memory=True)\nvalDL = DataLoader(valDS,batchSize*2,num_workers=4, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:04:40.712211Z","iopub.execute_input":"2022-03-23T08:04:40.712606Z","iopub.status.idle":"2022-03-23T08:04:40.720299Z","shell.execute_reply.started":"2022-03-23T08:04:40.712572Z","shell.execute_reply":"2022-03-23T08:04:40.719453Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing Batch data","metadata":{}},{"cell_type":"code","source":"# Visualizing Batch data\nfrom torchvision.utils import make_grid\n\ndef showBatch(DL):\n    for images, labels in DL:\n        fig, ax = plt.subplots(figsize=(12, 6))\n        ax.set_xticks([]); ax.set_yticks([]) #blank label axes\n        ax.imshow(make_grid(images, nrow=20).permute(1, 2, 0))\n        break","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:04:40.721854Z","iopub.execute_input":"2022-03-23T08:04:40.722427Z","iopub.status.idle":"2022-03-23T08:04:40.729670Z","shell.execute_reply.started":"2022-03-23T08:04:40.722391Z","shell.execute_reply":"2022-03-23T08:04:40.728797Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"showBatch(trainDL)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:04:40.731235Z","iopub.execute_input":"2022-03-23T08:04:40.731718Z","iopub.status.idle":"2022-03-23T08:04:44.424463Z","shell.execute_reply.started":"2022-03-23T08:04:40.731684Z","shell.execute_reply":"2022-03-23T08:04:44.423786Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:04:44.427619Z","iopub.execute_input":"2022-03-23T08:04:44.428215Z","iopub.status.idle":"2022-03-23T08:04:44.433843Z","shell.execute_reply.started":"2022-03-23T08:04:44.428176Z","shell.execute_reply":"2022-03-23T08:04:44.432731Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Some Useful Functions\ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images) # predictions\n        loss = F.cross_entropy(out, labels) # loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)\n        loss = F.cross_entropy(out, labels)   \n        acc = accuracy(out, labels) # accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs): # for epoch validation loss and accuracy\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean() # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean() # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch {} , train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:04:44.435668Z","iopub.execute_input":"2022-03-23T08:04:44.436019Z","iopub.status.idle":"2022-03-23T08:04:44.450669Z","shell.execute_reply.started":"2022-03-23T08:04:44.435968Z","shell.execute_reply":"2022-03-23T08:04:44.449685Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## CNN Model","metadata":{}},{"cell_type":"code","source":"# CNN Model\nclass MERCnnModel(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 64 x 40 x 40\n    \n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 128 x 20 x 20\n    \n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 256 x 10 x 10\n    \n            nn.Flatten(),\n            nn.Linear(256*10*10, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10))\n        \n    def forward(self, xb):\n        return self.network(xb)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:04:44.452634Z","iopub.execute_input":"2022-03-23T08:04:44.453018Z","iopub.status.idle":"2022-03-23T08:04:44.469679Z","shell.execute_reply.started":"2022-03-23T08:04:44.452981Z","shell.execute_reply":"2022-03-23T08:04:44.468763Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Model structure\nmodel = MERCnnModel()\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:04:44.471602Z","iopub.execute_input":"2022-03-23T08:04:44.472558Z","iopub.status.idle":"2022-03-23T08:04:44.727261Z","shell.execute_reply.started":"2022-03-23T08:04:44.472514Z","shell.execute_reply":"2022-03-23T08:04:44.726355Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Device selection","metadata":{}},{"cell_type":"code","source":"# to select GPU if available or else CPU\ndef get_default_device():\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n\n# to move tensor to selected device\ndef to_device(data, device): \n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\n# to wrap a dataloader to move data to the device\nclass DeviceDataLoader():\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self): # batch of data\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self): # no. of batches\n        return len(self.dl)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:04:44.728932Z","iopub.execute_input":"2022-03-23T08:04:44.729201Z","iopub.status.idle":"2022-03-23T08:04:44.738452Z","shell.execute_reply.started":"2022-03-23T08:04:44.729162Z","shell.execute_reply":"2022-03-23T08:04:44.737653Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()\nprint(\"Selected device:\",device)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:04:44.740330Z","iopub.execute_input":"2022-03-23T08:04:44.740900Z","iopub.status.idle":"2022-03-23T08:04:44.747412Z","shell.execute_reply.started":"2022-03-23T08:04:44.740851Z","shell.execute_reply":"2022-03-23T08:04:44.746606Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Wrapping training and validation dataloader\ntrain_dl = DeviceDataLoader(trainDL, device)\nval_dl = DeviceDataLoader(valDL, device)\nto_device(model, device);","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:04:44.748991Z","iopub.execute_input":"2022-03-23T08:04:44.749616Z","iopub.status.idle":"2022-03-23T08:04:44.790504Z","shell.execute_reply.started":"2022-03-23T08:04:44.749576Z","shell.execute_reply":"2022-03-23T08:04:44.789791Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad() # do not track gradient\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training phase \n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:04:44.791918Z","iopub.execute_input":"2022-03-23T08:04:44.792177Z","iopub.status.idle":"2022-03-23T08:04:44.803041Z","shell.execute_reply.started":"2022-03-23T08:04:44.792141Z","shell.execute_reply":"2022-03-23T08:04:44.802104Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"# Training\nmodel = to_device(MERCnnModel(), device)\nnum_epochs = 20\nopt_func = torch.optim.Adam\nlr = 0.001\nhistory = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:04:44.804567Z","iopub.execute_input":"2022-03-23T08:04:44.804888Z","iopub.status.idle":"2022-03-23T08:08:31.886830Z","shell.execute_reply.started":"2022-03-23T08:04:44.804845Z","shell.execute_reply":"2022-03-23T08:08:31.885923Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"## Validation Accuracy","metadata":{}},{"cell_type":"code","source":"# Validation accuracy\ndef plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:08:31.889301Z","iopub.execute_input":"2022-03-23T08:08:31.889835Z","iopub.status.idle":"2022-03-23T08:08:31.894657Z","shell.execute_reply.started":"2022-03-23T08:08:31.889796Z","shell.execute_reply":"2022-03-23T08:08:31.893971Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"plot_accuracies(history)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:08:31.896057Z","iopub.execute_input":"2022-03-23T08:08:31.896583Z","iopub.status.idle":"2022-03-23T08:08:32.096484Z","shell.execute_reply.started":"2022-03-23T08:08:31.896546Z","shell.execute_reply":"2022-03-23T08:08:32.095733Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Training and Validation loss","metadata":{}},{"cell_type":"code","source":"# Training and validation loss\ndef plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:08:32.097631Z","iopub.execute_input":"2022-03-23T08:08:32.098906Z","iopub.status.idle":"2022-03-23T08:08:32.105279Z","shell.execute_reply.started":"2022-03-23T08:08:32.098863Z","shell.execute_reply":"2022-03-23T08:08:32.104535Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"plot_losses(history)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:08:32.106678Z","iopub.execute_input":"2022-03-23T08:08:32.106962Z","iopub.status.idle":"2022-03-23T08:08:32.336145Z","shell.execute_reply.started":"2022-03-23T08:08:32.106927Z","shell.execute_reply":"2022-03-23T08:08:32.335417Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Prediction on testset","metadata":{}},{"cell_type":"code","source":"# Test set prediction\ndef predict_image(image, model):\n    xb = to_device(image.unsqueeze(0), device) # Convert to a batch of 1   \n    yb = model(xb)\n    _, preds  = torch.max(yb, dim=1) # pick class with highest probability\n    return dataset.classes[preds[0].item()] # return class label","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:10:05.553178Z","iopub.execute_input":"2022-03-23T08:10:05.553644Z","iopub.status.idle":"2022-03-23T08:10:05.561094Z","shell.execute_reply.started":"2022-03-23T08:10:05.553610Z","shell.execute_reply":"2022-03-23T08:10:05.559184Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"test_dataset = ImageFolder(datasetDir+'/test', transform=ToTensor())\nimage, label = test_dataset[112]\nplt.imshow(image.permute(1, 2, 0))\nprint('Label:', test_dataset.classes[label], ', Predicted:', predict_image(image, model))","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:10:10.316065Z","iopub.execute_input":"2022-03-23T08:10:10.316977Z","iopub.status.idle":"2022-03-23T08:10:10.549985Z","shell.execute_reply.started":"2022-03-23T08:10:10.316931Z","shell.execute_reply":"2022-03-23T08:10:10.548801Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"## Testset accuracy","metadata":{}},{"cell_type":"code","source":"# Test set accuracy\ntest_loader = DeviceDataLoader(DataLoader(test_dataset, batchSize*2), device)\nresult = evaluate(model, test_loader)\nprint(\"test loss:\",result['val_loss']) # in evaluate -> validation_step function its named val_loss and val_acc, so renamed here for testset\nprint(\"test accuracy:\",result['val_acc'])","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:10:18.221799Z","iopub.execute_input":"2022-03-23T08:10:18.222077Z","iopub.status.idle":"2022-03-23T08:10:20.388251Z","shell.execute_reply.started":"2022-03-23T08:10:18.222047Z","shell.execute_reply":"2022-03-23T08:10:20.387440Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"## Saving the model","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(),'MERCnn.pth')","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:14:52.988878Z","iopub.execute_input":"2022-03-23T08:14:52.989710Z","iopub.status.idle":"2022-03-23T08:14:53.279739Z","shell.execute_reply.started":"2022-03-23T08:14:52.989671Z","shell.execute_reply":"2022-03-23T08:14:53.279007Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"modelSaved = to_device(MERCnnModel(),device)\nmodelSaved.load_state_dict(torch.load('MERCnn.pth'))","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:14:57.878492Z","iopub.execute_input":"2022-03-23T08:14:57.878764Z","iopub.status.idle":"2022-03-23T08:14:58.230926Z","shell.execute_reply.started":"2022-03-23T08:14:57.878717Z","shell.execute_reply":"2022-03-23T08:14:58.230238Z"},"trusted":true},"execution_count":33,"outputs":[]}]}