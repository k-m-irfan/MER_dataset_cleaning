{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Micro-Expressions Classification","metadata":{}},{"cell_type":"code","source":"# importing required libraries\nimport os\nimport torch\nimport torchvision\nfrom torch.utils.data import random_split\nfrom torchvision.datasets import ImageFolder\nfrom torchvision.transforms import ToTensor\nimport torchvision.transforms as tt","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:17:45.459891Z","iopub.execute_input":"2022-03-23T08:17:45.460344Z","iopub.status.idle":"2022-03-23T08:17:45.464951Z","shell.execute_reply.started":"2022-03-23T08:17:45.460299Z","shell.execute_reply":"2022-03-23T08:17:45.464238Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"## Classes","metadata":{}},{"cell_type":"code","source":"# Classes\ndatasetDir = \"../input/micro-expressions/Micro_Expressions\"\nclasses = os.listdir(datasetDir + \"/train\")\nprint(\"Expression Labels: \",classes)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:17:45.466281Z","iopub.execute_input":"2022-03-23T08:17:45.466943Z","iopub.status.idle":"2022-03-23T08:17:45.487459Z","shell.execute_reply.started":"2022-03-23T08:17:45.466907Z","shell.execute_reply":"2022-03-23T08:17:45.486809Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"## Using Data Augmentation to increase dataset size (reflect-padding, and random-horizontal flip)","metadata":{}},{"cell_type":"code","source":"# data augmentation (reflect-padding, and random-horizontal flip)\ntfms = tt.Compose([tt.RandomCrop(80, padding=15, padding_mode='reflect'),\n                        tt.RandomHorizontalFlip(),\n                        tt.ToTensor()])\n#Loading the dataset as pyTorch Tensors\ndataset1 = ImageFolder(datasetDir+\"/train\",tfms)\ndataset2 = ImageFolder(datasetDir+\"/train\",transform=ToTensor())\n#Combining normal dataset and augmented dataset\ndataset = dataset1+dataset2\ndataset.classes = ['anger', 'disgust', 'fear', 'happiness', 'neutral', 'sadness', 'surprise']","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:17:45.489021Z","iopub.execute_input":"2022-03-23T08:17:45.489766Z","iopub.status.idle":"2022-03-23T08:17:46.323487Z","shell.execute_reply.started":"2022-03-23T08:17:45.489710Z","shell.execute_reply":"2022-03-23T08:17:46.322787Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing data","metadata":{}},{"cell_type":"code","source":"# visualising dataset\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\ndef show_image(image, label):\n    print(\"Label: \",dataset.classes[label])\n    plt.imshow(image.permute(1,2,0)) #rgb channel at last in matplot (1st in PyTorch Tensor)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:17:46.324504Z","iopub.execute_input":"2022-03-23T08:17:46.324739Z","iopub.status.idle":"2022-03-23T08:17:46.332299Z","shell.execute_reply.started":"2022-03-23T08:17:46.324707Z","shell.execute_reply":"2022-03-23T08:17:46.331638Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# an example from the dataset\nshow_image(*dataset[100])","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:17:46.334236Z","iopub.execute_input":"2022-03-23T08:17:46.334765Z","iopub.status.idle":"2022-03-23T08:17:46.569341Z","shell.execute_reply.started":"2022-03-23T08:17:46.334711Z","shell.execute_reply":"2022-03-23T08:17:46.567836Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"## Training and Validation Set","metadata":{}},{"cell_type":"code","source":"# Splitting dataset into training and validataion set using random_split\nrandomSeed = 3 #to always create same validation set\ntorch.manual_seed(randomSeed)\nvalSize = 2000\ntrainSize = len(dataset)-valSize\ntrainDS, valDS = random_split(dataset,[trainSize,valSize])\nprint(\"No. of training data: \",len(trainDS))\nprint(\"No. of validation data: \",len(valDS))","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:17:46.571405Z","iopub.execute_input":"2022-03-23T08:17:46.571865Z","iopub.status.idle":"2022-03-23T08:17:46.589837Z","shell.execute_reply.started":"2022-03-23T08:17:46.571826Z","shell.execute_reply":"2022-03-23T08:17:46.588802Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"#Creating data loaders\nfrom torch.utils.data.dataloader import DataLoader\nbatchSize = 200\ntrainDL = DataLoader(trainDS,batchSize,shuffle=True,num_workers=4, pin_memory=True)\nvalDL = DataLoader(valDS,batchSize*2,num_workers=4, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:17:46.592170Z","iopub.execute_input":"2022-03-23T08:17:46.592836Z","iopub.status.idle":"2022-03-23T08:17:46.604168Z","shell.execute_reply.started":"2022-03-23T08:17:46.592797Z","shell.execute_reply":"2022-03-23T08:17:46.603357Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing Batch data","metadata":{}},{"cell_type":"code","source":"# Visualizing Batch data\nfrom torchvision.utils import make_grid\n\ndef showBatch(DL):\n    for images, labels in DL:\n        fig, ax = plt.subplots(figsize=(12, 6))\n        ax.set_xticks([]); ax.set_yticks([]) #blank label axes\n        ax.imshow(make_grid(images, nrow=20).permute(1, 2, 0))\n        break","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:17:46.605558Z","iopub.execute_input":"2022-03-23T08:17:46.605863Z","iopub.status.idle":"2022-03-23T08:17:46.626537Z","shell.execute_reply.started":"2022-03-23T08:17:46.605826Z","shell.execute_reply":"2022-03-23T08:17:46.623624Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"showBatch(trainDL)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:17:46.628620Z","iopub.execute_input":"2022-03-23T08:17:46.628973Z","iopub.status.idle":"2022-03-23T08:17:49.161345Z","shell.execute_reply.started":"2022-03-23T08:17:46.628939Z","shell.execute_reply":"2022-03-23T08:17:49.160605Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:17:49.163121Z","iopub.execute_input":"2022-03-23T08:17:49.163703Z","iopub.status.idle":"2022-03-23T08:17:49.167924Z","shell.execute_reply.started":"2022-03-23T08:17:49.163666Z","shell.execute_reply":"2022-03-23T08:17:49.166885Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"# Some Useful Functions\ndef accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images) # predictions\n        loss = F.cross_entropy(out, labels) # loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)\n        loss = F.cross_entropy(out, labels)   \n        acc = accuracy(out, labels) # accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs): # for epoch validation loss and accuracy\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean() # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean() # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch {} , train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:17:49.171092Z","iopub.execute_input":"2022-03-23T08:17:49.171910Z","iopub.status.idle":"2022-03-23T08:17:49.185221Z","shell.execute_reply.started":"2022-03-23T08:17:49.171874Z","shell.execute_reply":"2022-03-23T08:17:49.184595Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":"## CNN Model","metadata":{}},{"cell_type":"code","source":"# CNN Model\nclass MERCnnModel(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.network = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 64 x 40 x 40\n    \n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 128 x 20 x 20\n    \n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2), # output: 256 x 10 x 10\n    \n            nn.Flatten(),\n            nn.Linear(256*10*10, 1024),\n            nn.ReLU(),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Linear(512, 10))\n        \n    def forward(self, xb):\n        return self.network(xb)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:17:49.186776Z","iopub.execute_input":"2022-03-23T08:17:49.187543Z","iopub.status.idle":"2022-03-23T08:17:49.201112Z","shell.execute_reply.started":"2022-03-23T08:17:49.187444Z","shell.execute_reply":"2022-03-23T08:17:49.200321Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# Model structure\nmodel = MERCnnModel()\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:17:49.202638Z","iopub.execute_input":"2022-03-23T08:17:49.203804Z","iopub.status.idle":"2022-03-23T08:17:49.441065Z","shell.execute_reply.started":"2022-03-23T08:17:49.203739Z","shell.execute_reply":"2022-03-23T08:17:49.440188Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"## Device selection","metadata":{}},{"cell_type":"code","source":"# to select GPU if available or else CPU\ndef get_default_device():\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n\n# to move tensor to selected device\ndef to_device(data, device): \n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\n# to wrap a dataloader to move data to the device\nclass DeviceDataLoader():\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self): # batch of data\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self): # no. of batches\n        return len(self.dl)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:17:49.442535Z","iopub.execute_input":"2022-03-23T08:17:49.443036Z","iopub.status.idle":"2022-03-23T08:17:49.454542Z","shell.execute_reply.started":"2022-03-23T08:17:49.442836Z","shell.execute_reply":"2022-03-23T08:17:49.453787Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"device = get_default_device()\nprint(\"Selected device:\",device)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:17:49.456104Z","iopub.execute_input":"2022-03-23T08:17:49.456397Z","iopub.status.idle":"2022-03-23T08:17:49.461598Z","shell.execute_reply.started":"2022-03-23T08:17:49.456361Z","shell.execute_reply":"2022-03-23T08:17:49.460820Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"# Wrapping training and validation dataloader\ntrain_dl = DeviceDataLoader(trainDL, device)\nval_dl = DeviceDataLoader(valDL, device)\nto_device(model, device);","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:17:49.463063Z","iopub.execute_input":"2022-03-23T08:17:49.463601Z","iopub.status.idle":"2022-03-23T08:17:49.508139Z","shell.execute_reply.started":"2022-03-23T08:17:49.463565Z","shell.execute_reply":"2022-03-23T08:17:49.507489Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad() # do not track gradient\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in range(epochs):\n        # Training phase \n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:17:49.509311Z","iopub.execute_input":"2022-03-23T08:17:49.509573Z","iopub.status.idle":"2022-03-23T08:17:49.519953Z","shell.execute_reply.started":"2022-03-23T08:17:49.509540Z","shell.execute_reply":"2022-03-23T08:17:49.519240Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"# Training\nmodel = to_device(MERCnnModel(), device)\nnum_epochs = 20\nopt_func = torch.optim.Adam\nlr = 0.001\nhistory = fit(num_epochs, lr, model, train_dl, val_dl, opt_func)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:17:49.523219Z","iopub.execute_input":"2022-03-23T08:17:49.523412Z","iopub.status.idle":"2022-03-23T08:21:33.706599Z","shell.execute_reply.started":"2022-03-23T08:17:49.523380Z","shell.execute_reply":"2022-03-23T08:21:33.705574Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":"## Validation Accuracy","metadata":{}},{"cell_type":"code","source":"# Validation accuracy\ndef plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:21:33.709155Z","iopub.execute_input":"2022-03-23T08:21:33.709722Z","iopub.status.idle":"2022-03-23T08:21:33.715415Z","shell.execute_reply.started":"2022-03-23T08:21:33.709678Z","shell.execute_reply":"2022-03-23T08:21:33.714222Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"plot_accuracies(history)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:21:33.717069Z","iopub.execute_input":"2022-03-23T08:21:33.717654Z","iopub.status.idle":"2022-03-23T08:21:33.940356Z","shell.execute_reply.started":"2022-03-23T08:21:33.717614Z","shell.execute_reply":"2022-03-23T08:21:33.939625Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"## Training and Validation loss","metadata":{}},{"cell_type":"code","source":"# Training and validation loss\ndef plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:21:33.941794Z","iopub.execute_input":"2022-03-23T08:21:33.942085Z","iopub.status.idle":"2022-03-23T08:21:33.947960Z","shell.execute_reply.started":"2022-03-23T08:21:33.942045Z","shell.execute_reply":"2022-03-23T08:21:33.946930Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"plot_losses(history)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:21:33.949400Z","iopub.execute_input":"2022-03-23T08:21:33.949890Z","iopub.status.idle":"2022-03-23T08:21:34.180290Z","shell.execute_reply.started":"2022-03-23T08:21:33.949838Z","shell.execute_reply":"2022-03-23T08:21:34.179602Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"## Prediction on testset","metadata":{}},{"cell_type":"code","source":"# Test set prediction\ndef predict_image(image, model):\n    xb = to_device(image.unsqueeze(0), device) # Convert to a batch of 1   \n    yb = model(xb)\n    _, preds  = torch.max(yb, dim=1) # pick class with highest probability\n    return dataset.classes[preds[0].item()] # return class label","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:24:22.278681Z","iopub.execute_input":"2022-03-23T08:24:22.279416Z","iopub.status.idle":"2022-03-23T08:24:22.286061Z","shell.execute_reply.started":"2022-03-23T08:24:22.279374Z","shell.execute_reply":"2022-03-23T08:24:22.284020Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"test_dataset = ImageFolder(datasetDir+'/test', transform=ToTensor())\nimage, label = test_dataset[112]\nplt.imshow(image.permute(1, 2, 0))\nprint('Label:', test_dataset.classes[label], ', Predicted:', predict_image(image, model))","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:24:24.486580Z","iopub.execute_input":"2022-03-23T08:24:24.486857Z","iopub.status.idle":"2022-03-23T08:24:24.749354Z","shell.execute_reply.started":"2022-03-23T08:24:24.486825Z","shell.execute_reply":"2022-03-23T08:24:24.748622Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"## Testset accuracy","metadata":{}},{"cell_type":"code","source":"# Test set accuracy\ntest_loader = DeviceDataLoader(DataLoader(test_dataset, batchSize*2), device)\nresult = evaluate(model, test_loader)\nprint(\"test loss:\",result['val_loss']) # in evaluate -> validation_step function its named val_loss and val_acc, so renamed here for testset\nprint(\"test accuracy:\",result['val_acc'])","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:27:01.430625Z","iopub.execute_input":"2022-03-23T08:27:01.431324Z","iopub.status.idle":"2022-03-23T08:27:03.718167Z","shell.execute_reply.started":"2022-03-23T08:27:01.431286Z","shell.execute_reply":"2022-03-23T08:27:03.717416Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"## Saving the model","metadata":{}},{"cell_type":"code","source":"# torch.save(model.state_dict(),'MERCnn.pth')","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:27:07.047474Z","iopub.execute_input":"2022-03-23T08:27:07.047729Z","iopub.status.idle":"2022-03-23T08:27:07.052470Z","shell.execute_reply.started":"2022-03-23T08:27:07.047700Z","shell.execute_reply":"2022-03-23T08:27:07.051679Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# modelSaved = to_device(MERCnnModel(),device)\n# modelSaved.load_state_dict(torch.load('MERCnn.pth'))","metadata":{"execution":{"iopub.status.busy":"2022-03-23T08:27:10.709386Z","iopub.execute_input":"2022-03-23T08:27:10.709650Z","iopub.status.idle":"2022-03-23T08:27:10.713551Z","shell.execute_reply.started":"2022-03-23T08:27:10.709620Z","shell.execute_reply":"2022-03-23T08:27:10.712761Z"},"trusted":true},"execution_count":63,"outputs":[]}]}